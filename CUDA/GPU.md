
#### CPU/GPU 구조![[Pasted image 20250226203439.png]]

#### Many-[[Thread]](Many-Core) 전략
- 병렬 프로그램의 처리량에 더 초점을 맞춤
- 대량의 스레드를 사용하며, 세대마다 스레드의 수가 증가하고 있음
- 특히 GPU는 부동소수점 연산 성능을 주도하고 있고, 부동소수점 연산 처리량이 멀티코어 CPU의 약 10배 정도 높음

#### 메모리 대역폭(bandwidth)
- 많은 어플리케이션의 속도는 메모리 시스템에서 프로세서로 전달해야 하는 메모리의 비율에 따라서 제한됨
- GPU는 graphics frame buffer 요구사항 때문에 매우 많은 양의 데이터를 DRAM의 내외부로 이동할 수 있음
- CPU는 legacy OS, 어플리케이션, I/O 디바이스들의 요구사항을 만족해야 하므로 메모리 대역폭을 늘리지 못함
- 따라서 CPU에 비해 더 간단한 메모리 모델을 사용할 수 있고, legacy 소프트웨어에 대한 제약 사항이 거의 없어서 상대적으로 쉽게 메모리 대역폭을 높일 수 있음

#### 설계 철학
- Throughput-Oriented Design
- 빠르게 성장하는 비디오 게임 산업에 의해서 형성됨
	- 고급 게임들의 비디오 프레임 당 엄청난 수의 부동소수점 연산을 수행할 수 있어야 경쟁에서 이길 수 있었음
- 칩의 면적과 전력을 부동소수점 연산에 최대로 할당하기 위한 여러 방법들을 고안해내고, 결과적으로 지연 시간(latency)을 줄이는 것보다, **처리량을 늘리는 것**이 더 효율적이라는 것을 발견하게됨
- 일반적인 해법은 **대량의 스레드의 실행 처리량을 최적화**하는 것
	- 이 설계는 메모리 채널과 산술 연산이 긴 지연시간(long-latency)를 갖게 함으로써 칩 공간과 전력을 절약하게 됨
	- 칩 설계자들은 이렇게 절약한 공간과 전력을 사용하여 총 연산 처리량을 증가시킬 수 있음

#### GPU의 대량 병렬 처리 구조
- 높은 처리량을 목표로 설계 -> 매우 많은 수의 스레드가 동시에 실행되도록 설계되어 있음
	- 수천 개의 스레드를 동시에 실행할 수 있도록 대량의 연산 유닛(CUDA core, [[ALU]])을 배치
	- CPU보다 상대적으로 단순한 제어 로직을 사용하여 트랜지스터와 전력을 연산 유닛에 집중
	- 메모리 엑세스가 느려도 대기 중인 다른 스레드들이 실행을 계속하도록 설계
- 대량의 스레드를 실행하는 것을 전제로 하므로, 단일 스레드의 지연시간은 희생할 수 있는 요소임
	- 스레드 다중화(thread-level parallelism, TLP)를 활용하여 한 스레드가 메모리 접근으로 인해 대기하는 동안, 다른 스레드의 실행을 교대로 수행함
	- 즉, 메모리 지연시간을 스레드 다중화로 숨길 수 있음 -> 복잡한 캐시 계층구조나 비쌴 저지연 메모리 사용 필요성 X
	- 따라서 느린 메모리 채널을 사용하여 칩 공간과 전력을 절약하고, 대신 높은 대역폭을 확보하여 대량의 데이터 처리량을 유지
- 긴 파이프라인을 가진 산술 유닛을 사용하여 대량의 연산을 지속적으로 수행하도록 설계되어 있음
	- [[ALU]]의 긴 지연시간을 허용하는 대신, 한 번에 많은 연산을 처리할 수 있도록 실행 유닛을 대량으로 배치
	- 따라서 단일 연산의 지연시간이 길어도, 연산 유닛을 더 많이 배치하여 전체 처리량을 증가시키고, 칩 공간과 전력을 절약
		- 복잡한 분기 예측이나 명령어 스케쥴링 같은 복잡한 제어 로직이 없으므로, 칩 공간을 절약할 수 있음